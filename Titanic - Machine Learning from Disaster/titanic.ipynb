{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.compose import ColumnTransformer \nfrom sklearn.impute import SimpleImputer\nimport category_encoders as ce\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.pipeline import make_pipeline, Pipeline\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.base import BaseEstimator","metadata":{"execution":{"iopub.status.busy":"2022-05-24T12:03:53.360303Z","iopub.execute_input":"2022-05-24T12:03:53.360673Z","iopub.status.idle":"2022-05-24T12:03:54.745444Z","shell.execute_reply.started":"2022-05-24T12:03:53.360580Z","shell.execute_reply":"2022-05-24T12:03:54.744630Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ntrain_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-05-24T12:03:57.736458Z","iopub.execute_input":"2022-05-24T12:03:57.737264Z","iopub.status.idle":"2022-05-24T12:03:57.753860Z","shell.execute_reply.started":"2022-05-24T12:03:57.737203Z","shell.execute_reply":"2022-05-24T12:03:57.752961Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from pandas_profiling import ProfileReport\ntrain_profile = ProfileReport(train_data, title=\"Train Data\")\ndisplay(train_profile)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T12:04:00.284353Z","iopub.execute_input":"2022-05-24T12:04:00.284658Z","iopub.status.idle":"2022-05-24T12:04:18.820740Z","shell.execute_reply.started":"2022-05-24T12:04:00.284625Z","shell.execute_reply":"2022-05-24T12:04:18.819783Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nclass CabinOneHotEncoder(BaseEstimator):\n\n    def __init__(self):\n        self.ct = []\n        pass\n\n    def fit(self, documents, y=None):\n        return self\n\n    def transform(self, X):\n        def process(x):\n            if isinstance(x, float) and np.isnan(x):\n                return (\"nan\", 0, 0, 0)\n            sp = x.split()\n            pre = \"\"\n            num = []\n            for s in sp:\n                if s[0] not in pre:\n                    pre += s[0]\n                if len(s)>1:\n                    num.append(int(s[1:]))\n            if len(num) == 0:\n                num = [0]\n            return (pre, len(sp), min(num), max(num))\n        x = pd.DataFrame(X[\"Cabin\"].map(lambda x: process(x)).tolist(), columns=[\"Cabin_Letter\", \"Cabin_split\", \"Cabin_min\", \"Cabin_max\"])\n        if len(self.ct) == 0:\n            self.ct = x[\"Cabin_Letter\"].unique()\n            ct = self.ct\n        else:\n            ct = self.ct\n        def ohe_Cabin(x):\n            lt = [0] * len(ct)\n\n            for c in x:\n                for i, v in enumerate(ct):\n                    if c in v:\n                        lt[i] = 1\n            return lt\n        x2 = pd.DataFrame(x[\"Cabin_Letter\"].map(lambda x: ohe_Cabin(x)).tolist(), columns=[\"Cabin_Letter_\"+c for c in ct])\n        return pd.concat([X, x, x2], axis=1).drop(columns=[\"Cabin\", \"Cabin_Letter\"])\n    \n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.where(train_data['Age'].isna())[0])\ntrain_data.loc[[5,17,19]]\ntrain_data[(train_data[\"Embarked\"]==\"Q\") & (train_data[\"Pclass\"]==3) & (train_data[\"SibSp\"]==0)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# define the class OutletTypeEncoder\n# This will be our custom transformer that will create 3 new binary columns\n# custom transformer must have methods fit and transform\nclass PdOneHotEncoder(BaseEstimator):\n\n    def __init__(self, categorical_cols):\n        self.categorical_cols = categorical_cols\n        pass\n\n    def fit(self, documents, y=None):\n        return self\n\n    def transform(self, x_dataset):\n        print(x_dataset)\n        pd.get_dummies(x_dataset, columns = self.categorical_cols)\n        \n        return x_dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ncat_pipe = make_pipeline(\n    SimpleImputer(strategy=\"constant\", fill_value=\"nan\"),\n    OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n)\n\npre_process = ColumnTransformer(remainder='passthrough',\n                                transformers=[\n                                    ('drop_columns', 'drop', ['Name', 'PassengerId', 'Ticket', \"Embarked\"]),\n                                    (\"simple_imputer_age\", SimpleImputer(strategy=\"mean\"), [\"Age\"]),\n                                    ('cat_pipe', cat_pipe, [\"Sex\", \"Pclass\"]),\n                                ])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_pipeline = Pipeline(steps=[\n    (\"cabin\", CabinOneHotEncoder()),\n    ('pre_processing',pre_process),\n#     ('random_forest', RandomForestClassifier(max_depth=10,random_state=2))\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = model_pipeline.fit_transform(train_data)\nY = train_data[\"Survived\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nXX = CabinOneHotEncoder().transform(train_data)\nprint(XX.columns)\nprint(XX[\"Cabin_Letter_C\"])\nsns.scatterplot(x=\"Cabin_Letter_C\", y=\"Survived\", data=XX)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_pipeline.fit(train_data, Y)\nfrom sklearn.model_selection import GridSearchCV\nparam_grid = {\n    \"n_estimators\": [10, 100, 200, 500],\n    \"max_depth\": [10, 100, 200],\n    \"min_samples_split\": [2,4, 7, 10]\n}\nclf = GridSearchCV(estimator=RandomForestClassifier(), param_grid=param_grid, n_jobs=-1)\nclf.fit(X, Y)\nclf.best_score_, clf.best_estimator_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import lightgbm as lgb\nparam_grid = {\n    \"n_estimators\": [10, 100, 200, 500],\n    \"max_depth\": [-5, 10, 100, 200],\n    \"learning_rate\": [0.05, 0.09, 0.1, 0.2]\n}\nmodel = lgb.LGBMClassifier(random_state=42)\nclf = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\nclf.fit(X, Y)\nclf.best_score_, clf.best_estimator_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SimpleImputer(strategy=\"mean\").fit_transform(test_data[[\"Fare\"]])\ntest_data.at[test_data[\"Fare\"].isna(), \"Fare\"] = 9.33\ntX = model_pipeline.transform(test_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res = clf.predict(tX)\noutput = test_data[[\"PassengerId\"]]\noutput[\"Survived\"] = res\noutput.to_csv(\"predicted_v6.csv\", index=False)\nprev_out = pd.read_csv(\"predicted.csv\")\nsum(prev_out[\"Survived\"] == output[\"Survived\"])/output.shape[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}